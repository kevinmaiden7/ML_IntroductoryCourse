{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 5 - Parte 2\n",
    "\n",
    "### Máquinas de Vectores de Soporte\n",
    "\n",
    "### 2019-II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer Integrante: Kevin Martínez Gallego\n",
    "#### Segundo Integrante: Andrés Mauricio Álvarez Ortiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy import round\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Limipiar base de datos y completar código\n",
    "\n",
    "En este ejercicio usaremos la regresión por vectores de soporte para resolver el problema de regresión de la base de datos AirQuality (https://archive.ics.uci.edu/ml/datasets/Air+Quality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limipiar base de datos\n",
    "La siguiente celda de código limpia la base de datos de todos sus datos faltantes y la deja lista en la variable DataBase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Cargar** la base de datos\n",
    "2. **Quitar** todos registros de la base de datos que son perdidos y están marcados como -200, es decir, donde haya un valor -200 eliminaremos el registro.\n",
    "3.  Ya hemos eliminado los registros con valor de la variable de salida perdido. Ahora vamos a **imputar los valores perdidos** en cada una de las características.\n",
    "4. **Verificar** si quedaron valores faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim de la base de datos original: (9357, 13)\n",
      "\n",
      "Hay 366 valores perdidos en la variable de salida.\n",
      "\n",
      "Dim de la base de datos sin las muestras con variable de salida perdido (8991, 13)\n",
      "\n",
      "Procesando imputación de valores perdidos en las características . . .\n",
      "\n",
      "Imputación finalizada.\n",
      "\n",
      "No hay valores perdidos en la base de datos. Ahora se puede procesar. La base de datos está en la variable DataBase\n"
     ]
    }
   ],
   "source": [
    "#Paso 1: Cargar\n",
    "db = np.loadtxt('BDatos/AirQuality.data',delimiter='\\t')  # Assuming tab-delimiter\n",
    "print(\"Dim de la base de datos original: \" + str(np.shape(db)))\n",
    "db = db.reshape(9357,13)\n",
    "\n",
    "DataBase = db\n",
    "\n",
    "#Paso 2: Quitar\n",
    "j = 0\n",
    "for i in range(0,np.size(db,0)):\n",
    "    if -200 == db[i,12]:\n",
    "        #print i\n",
    "        j+=1\n",
    "        DataBase = np.delete(DataBase,i,0)\n",
    "    \n",
    "print (\"\\nHay \" + str(j) + \" valores perdidos en la variable de salida.\")\n",
    "\n",
    "print (\"\\nDim de la base de datos sin las muestras con variable de salida perdido \"+ str(np.shape(DataBase)))\n",
    "\n",
    "\n",
    "##Paso 3: Imputar\n",
    "print (\"\\nProcesando imputación de valores perdidos en las características . . .\\n\")\n",
    "\n",
    "\n",
    "for k in range(0,np.size(DataBase,0)):\n",
    "    for w in range(0,13):\n",
    "        if -200 == DataBase[k,w]:\n",
    "            DataBase[k,w] = round(np.mean(DataBase[:,w])) ## Se imputa con la media de toda la caracteristicas\n",
    "        \n",
    "print (\"Imputación finalizada.\\n\")\n",
    "\n",
    "\n",
    "##Paso 4: Verificar\n",
    "\n",
    "hay_missed_values = False\n",
    "for i in range(0,np.size(DataBase,0)):\n",
    "    if -200 in DataBase[i,:]:\n",
    "        hay_missed_values = True\n",
    "if(hay_missed_values):\n",
    "    print (\"Hay valores perdidos\")\n",
    "else:\n",
    "    print (\"No hay valores perdidos en la base de datos. Ahora se puede procesar. La base de datos está en la variable DataBase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base de datos final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataBase[:,0:12]\n",
    "\n",
    "Y = DataBase[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8991, 12)\n",
      "(8991,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función Mean Absolute Percentage Error para los problemas de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_est,Y):\n",
    "    ind = Y != 0 #Remueve los elementos que son cero en la variable deseada\n",
    "    N = np.size(Y[ind])\n",
    "    mape = np.sum(abs((Y_est[ind].reshape(N,1) - Y[ind].reshape(N,1))/(Y[ind].reshape(N,1)+np.finfo(np.float).eps)))/N\n",
    "    return mape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Complete el código\n",
    "\n",
    "A continuación complete el siguiente código para crear el modelo vectores de soporte(SVM) para regresión usando la librería sklearn. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "import time\n",
    "\n",
    "def execute_SVR(kernel, regParam, gamma):\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    #Implemetamos la metodología de validación cross validation con 5 folds\n",
    "    Folds = 5\n",
    "    Errores = np.ones(Folds)\n",
    "    porcentajeVectores = np.zeros(Folds)\n",
    "    j = 0\n",
    "    kf = KFold(n_splits=Folds)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        Xtrain, Xtest = X[train_index], X[test_index]\n",
    "        Ytrain, Ytest = Y[train_index], Y[test_index]  \n",
    "\n",
    "        #Complete el código\n",
    "                \n",
    "        #Normalizamos los datos\n",
    "        scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "        Xtrain = scaler.transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        if(kernel == 'rbf'):\n",
    "            model = SVR(C=regParam, kernel='rbf', gamma=gamma).fit(Xtrain, Ytrain)\n",
    "        else:\n",
    "            model = SVR(C=regParam, kernel=kernel).fit(Xtrain, Ytrain)\n",
    "\n",
    "        porcentajeVectores[j] = np.sum(len(model.support_))/np.shape(Xtrain)[0]\n",
    "            \n",
    "        # Validación del modelo\n",
    "        Y_pred = model.predict(Xtest)\n",
    "\n",
    "        Errores[j] = MAPE(Y_pred, Ytest)\n",
    "        j+=1\n",
    "\n",
    "    error = round(np.mean(Errores),3)\n",
    "    std_error = round(np.std(Errores),3)\n",
    "    vectores_soporte = round(np.mean(porcentajeVectores),3)\n",
    "    \n",
    "    print(\"\\nError de validación: \" + str(error) + \" +/- \" + str(std_error) + \", % vectores de soporte: \" + str(vectores_soporte))\n",
    "\n",
    "    print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "    \n",
    "    return(str(error), str(std_error), str(vectores_soporte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación: 0.226 +/- 0.111, % vectores de soporte: 0.219\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 7.069697380065918 segundos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('0.226', '0.111', '0.219')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_SVR('rbf', 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Experimentos\n",
    "\n",
    "Una vez complete el código, realice las simulaciones necesarias para llenar la tabla siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'Kernel' : pd.Series(['lineal','lineal','lineal','lineal','lineal','lineal','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf']),\n",
    "    'C' : pd.Series([0.001,0.01,0.1,1,10,100,0.001,0.001,0.001,0.01,0.01,0.01,0.1,0.1,0.1,1,1,1,10,10,10,100,100,100]),\n",
    "    'gamma' : pd.Series([0,0,0,0,0,0,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1,0.01,0.1,1])})\n",
    "df_types[\"MAPE Promedio\"] = \"\"\n",
    "df_types[\"Intervalo de confianza\"] = \"\"\n",
    "df_types[\"% de Vectores de Soporte\"] = \"\"\n",
    "df_types.set_index(['Kernel','C','gamma'], inplace=True)\n",
    "#df_types[\"MAPE Promedio\"][23] = \"0.2259\"\n",
    "#df_types[\"Intervalo de confianza\"][23] = \"0.1109\"\n",
    "#df_types[\"% de Vectores de Soporte\"][23] = \"0.2191\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "\n",
    "index = 0\n",
    "kernel = 'linear'\n",
    "regParam = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "gammaValues = [0.01, 0.1, 1]\n",
    "\n",
    "for i in range(np.size(regParam)):\n",
    "    eff, std_eff, sv = execute_SVR(kernel, regParam[i], -1)\n",
    "    df_types[\"MAPE Promedio\"][index] = eff\n",
    "    df_types[\"Intervalo de confianza\"][index] = std_eff\n",
    "    df_types[\"% de Vectores de Soporte\"][index] = sv\n",
    "    index += 1\n",
    "\n",
    "kernel = 'rbf'\n",
    "for i in range(np.size(regParam)):\n",
    "    C = regParam[i]\n",
    "    for j in range(np.size(gammaValues)):\n",
    "        eff, std_eff, sv = execute_SVR(kernel, C, gammaValues[j])\n",
    "        df_types[\"MAPE Promedio\"][index] = eff\n",
    "        df_types[\"Intervalo de confianza\"][index] = std_eff\n",
    "        df_types[\"% de Vectores de Soporte\"][index] = sv\n",
    "        index += 1\n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Completar preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 ¿Cuál es la finalidad de usar las funciones kernel en el modelo SVM?\n",
    "\n",
    "R/: La idea de la función Kernel es mapear las muestras, que originalmente estan en un espacio d-dimensional, a un espacio de mayor dimensión en el cual aumenta la capacidad del modelo de realizar predicciones. Para un problema de clasificación, la función Kernel puede hacer posible que clases traslapadas en el espacio orginal sean linealmente separables en el nuevo espacio. Para un problema de regresión, la función Kernel puede permitir encontrar una curva más representativa de las muestras de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 ¿En este caso el porcentaje de vectores de soporte provee una información similar que en el problema de clasificación? Explique su respuesta.\n",
    "\n",
    "R/: Si. Porque en regresión, los vectores de soporte son las muestras que están fuera del epsilon-tubo o justo en el limite; es decir, las muestras que son \"difíciles\" de ajustar a la curva. En clasificación, los vectores de soporte son las muestras que están dentro del margen o justo en el límite; es decir, las muestras que son \"difíciles\" de clasificar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Realice una gráfica de las salidas reales vs las predicciones del modelo SVM, para evaluar visualmente el desempeño del mismo. Esto solo para la configuración en la cuál se encontró el menor error.\n",
    "\n",
    "Complete el código para hacer la gráfica aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
