{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 1 - Parte 2\n",
    "\n",
    "### Regresión logística y Funciones Discriminantes Gausianas\n",
    "\n",
    "### 2019 - II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En este archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: No olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy import stats\n",
    "\n",
    "import numpy.matlib as matlib\n",
    "\n",
    "import math\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer integrante:\n",
    "Nombre: Kevin Martínez Gallego\n",
    "\n",
    "\n",
    "#### Segundo integrante:\n",
    "\n",
    "Nombre: Andrés Mauricio Álvarez Ortiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "El problema de *clasificación* que están cargados en el archivo `DatosClases.mat`. Las variables o caracterísicas son guardadas en  X y la variable de salida es guardada en la variable Y. \n",
    "\n",
    "Responda las siguientes preguntas y grafique los datos usando la funci&oacute;n [scatter](https://matplotlib.org/gallery/shapes_and_collections/scatter.html) de matplotlib y responda las siguientes preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('DB/DatosClases.mat')\n",
    "X = mat['X'] # Matriz X de muestras con las características\n",
    "Y = mat['Y'] # Variable de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 ¿Cu&aacute;ntas clases tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 ¿Cu&aacute;ntas caracter&iacute;sticas tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 ¿Cu&aacute;ntas muestras tiene el problema?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Gráfica del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y[:,0], cmap='Accent');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 ¿El problema es linealmente separable?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El problema no es linealmente separable porque no es posible encontrar una función lineal que divida perfectamente el\n",
    "espacio de características y dejar los conjuntos de muestras de cada clase separados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Completar código\n",
    "\n",
    "En este laboratorio se va a realizar un procedimiento análogo al laboratorio anterior, pero con el modelo de *regresión logística* que sirve para resolver problemas de clasificación (en principio biclase).\n",
    "\n",
    "Analice los siguientes métodos a la luz de la teoría vista para el modelo de regresión logística, tales como la función de activación (<font color='blue'>sigmoidal</font>), el modelo de regresión logística (<font color='blue'>logistic_regression</font>), potencia del polinomio y el cálculo del error en clasificación (<font color='blue'>error_logistic</font>) y el gradiente descendente. \n",
    "\n",
    "Una vez comprenda su funcionamiento proceda a realizar lo siguiente:\n",
    "\n",
    "1. Completar el código del método de <font color='blue'>gradiente_descedente_logistic</font> con la regla de actualización de los parámetros para el problema de clasificación\n",
    "\n",
    "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
    "\n",
    "Nota: Para el problema de clasificación tenga presente que si ya implementó la regla de actualización de parámetros para el modelo de regresión polinomial múltiple, este punto es trivial, puesto que sólo tiene que incluir la función sigmoidal tal como lo vimos en la teoría.\n",
    "\n",
    "2. Graficar el error de clasificación durante las iteraciones del algoritmo. La gráfica debe llevar título y los correspondientes nombres de los ejes.\n",
    "\n",
    "Nota: Observe que el método logistic_regression ya hace el llamado a la función sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de activación Sigmoidal\n",
    "def sigmoidal(z):\n",
    "    \n",
    "    #Complete la siguiente línea con el código para calcular la salida de la función sigmoidal\n",
    "    s = np.exp(z)/(1 + np.exp(z))    \n",
    "    return s\n",
    "\n",
    "#Modelo Regresión logística\n",
    "def logistic_regression(X, W):\n",
    "    #Con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\n",
    "    Yest = np.dot(X,W)\n",
    "    \n",
    "    Y_lest = sigmoidal(Yest)\n",
    "    \n",
    "    #Se asignan los valores a 1 o 0 según el modelo de regresión logística definido\n",
    "    pos = 0\n",
    "    for tag in Y_lest:\n",
    "        \n",
    "        if tag > 0.5:\n",
    "            Y_lest[pos] = 1\n",
    "        elif tag < 0.5:\n",
    "            Y_lest[pos] = 0\n",
    "        \n",
    "        pos += 1\n",
    "    \n",
    "    return Y_lest    #Y estimado: Esta variable contiene ya tiene la salida de sigm(f(X,W))\n",
    "\n",
    "\n",
    "#En este laboratorio solo trabajaremos el caso lineal (grado 1), pero se pueden probar otras fronteras\n",
    "def potenciaPolinomio(X,grado):\n",
    "    X2 = X\n",
    "    \n",
    "    if grado != 1:\n",
    "        for i in range(2,grado+1):\n",
    "            Xadd = X**i\n",
    "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
    "    \n",
    "    return X2\n",
    "\n",
    "\n",
    "#Calcular el error del modelo de regresión logística\n",
    "#Si es diferente el Y_estimado con el Y_real cuenta como un error\n",
    "def error_logistic(Y_lest, Y):\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    \n",
    "    error = error/np.size(Y)\n",
    "    \n",
    "    #print (\"La eficiencia en esta iteración fue: \"+str(1-error)+'\\n')\n",
    "    \n",
    "    return error\n",
    "\n",
    "\"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "X: Matriz de datos extendida.\n",
    "W: Vector de parámetros del modelo\n",
    "eta: Taza de aprendizaje\n",
    "\"\"\"\n",
    "def gradiente_descendente_logistic(X,Y,grado,eta):\n",
    "    \n",
    "    #Extendemos la matriz\n",
    "    unos = np.array([np.ones(np.size(X,0))]\n",
    "                   )\n",
    "    #Concatenar el vector de unos con la matriz X\n",
    "    X = np.concatenate((unos.T, X), axis=1)\n",
    "    X = X.reshape(np.size(X,0),np.size(X,1))\n",
    "    \n",
    "    Y = Y.reshape(np.size(Y), 1)\n",
    "    \n",
    "    #Tomamos el número de variables del problema\n",
    "    d = np.size(X,1)\n",
    "\n",
    "    #Tomamos el número de muestras de la base de datos\n",
    "    N = np.size(X,0)\n",
    "    \n",
    "    #Inicializamos el vector de parámetros aleatoriamente\n",
    "    #Want = np.random.randn(d)\n",
    "    W = np.zeros(d)\n",
    "    W = W.reshape(np.size(W),1)\n",
    "\n",
    "    #eta = eta\n",
    "    \n",
    "    iteraciones = 1000\n",
    "    errores = np.zeros(iteraciones)\n",
    "    \n",
    "    for iter in range(iteraciones):\n",
    "\n",
    "        Y_estimado = logistic_regression(X,W)\n",
    "        #Error en clasificación\n",
    "        error = error_logistic(Y_estimado,Y)\n",
    "        errores[iter] = error\n",
    "\n",
    "        #Aquí debe completar el código con la regla de actualización de los parámetros W para regresión\n",
    "        #logística. Tenga en cuenta los nombres de las variables ya creadas: W, X, Y\n",
    "        temp = Y_estimado - np.array(Y)\n",
    "        temp2 = np.dot(X.T, temp)\n",
    "        wsig = W - eta*temp2/N\n",
    "        W = wsig\n",
    "    \n",
    "    #Aquí debe completar el código para realizar la gráfica del error de clasificación vs. iteraciones\n",
    "    plt.plot(errores)\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Error a través de las iteraciones')\n",
    "    plt.show()\n",
    "    \n",
    "    print ('Vector de parámetros del modelo:\\n')\n",
    "    print (W)\n",
    "    print ('\\nError de entrenamiento = ' + str(errores[-1]))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Entrenamiento\n",
    "\n",
    "1. Complete el código de la siguiente celda llamando el método <font color='blue'>gradiente_descedente_logistic</font>, se debe pasar los parámetros que corresponde con la tabla de resultados de abajo\n",
    "2. Ejecute el entrenamiento\n",
    "3. Llene la tabla de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de parámetros del modelo:\n",
      "\n",
      "[[ 0.04      ]\n",
      " [-0.01820266]\n",
      " [ 0.02057001]\n",
      " [ 0.31464721]\n",
      " [ 0.29322399]\n",
      " [-0.00914343]\n",
      " [ 0.01970678]]\n",
      "\n",
      "Error de entrenamiento = 0.0\n",
      "\n",
      "Error durante la prueba = 0.5\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import math\n",
    "N = np.size(X,0)\n",
    "\n",
    "# #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n",
    "grado = 3\n",
    "X2 = potenciaPolinomio(X,grado)\n",
    "\n",
    "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
    "random.seed(1)\n",
    "ind=np.random.permutation(N)\n",
    "Xtrain = X2[ind[0:int(math.ceil(0.7*N))],:]\n",
    "Xtest = X2[ind[int(math.ceil(0.7*N)):N],:]\n",
    "Ytrain = Y[ind[0:int(math.ceil(0.7*N))]]\n",
    "Ytest = Y[ind[int(math.ceil(0.7*N)):N]]\n",
    "\n",
    "#Normalizamos los datos\n",
    "media = np.mean(Xtrain)\n",
    "desvia = np.std(Xtrain)\n",
    "Xtrain = stats.stats.zscore(Xtrain)\n",
    "Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "eta = 1\n",
    "\n",
    "#Complete la siguiente línea de código llamando el método gradiente_descendente con sus respectivos argumentos\n",
    "W = gradiente_descendente_logistic(Xtrain,Ytrain,grado,eta)\n",
    "\n",
    "#Evaluamos las predicciones del modelo con los datos de test\n",
    "unos = np.array([np.ones(np.size(Xtest,0))])\n",
    "Xtest2 = np.concatenate((unos.T, Xtest), axis=1)\n",
    "Xtest2 = Xtest2.reshape(np.size(Xtest2,0),np.size(Xtest2,1))\n",
    "Yest = logistic_regression(Xtest2, W)\n",
    "Error = error_logistic(Yest,Ytest)\n",
    "print('\\nError durante la prueba = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Tasa de aprendizaje' : pd.Series(['1', '1', '1', '1', '1', '0.1', '0.1', '0.1', '0.1', '0.1', '0.001', '0.001', '0.001', '0.001', '0.001']),\n",
    "    'Grado del polinomio' : pd.Series([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])})\n",
    "df_types[\"Error_Entrenamiento\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types.set_index(['Tasa de aprendizaje','Grado del polinomio'], inplace=True)\n",
    "df_types[\"Error_Entrenamiento\"][2] = \"0.0\"\n",
    "df_types[\"Error_Prueba\"][2] = \"0.5\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "4.1 Escriba el modelo completo con sus variables y coeficientes de $f(\\textbf{x},\\textbf{w})$ con la mejor frontera de decisión que encontró según la tabla de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Basado en el valor del error obtenido, ¿cu&aacute;ntas muestras de entrenamiento y de prueba clasifica mal el modelo? (un valor para cada conjunto). Nota. Escriba en una celda el código con el cuál obtuvo la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza un clasificador basado en Funciones Discriminantes Gaussianas para resolver el mismo problema de clasificación. Ejecute el código y responda las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistribucionGaussiana(X,Mu,Sigma):\n",
    "    \n",
    "    SigmaInversa = np.linalg.inv(np.array(Sigma))\n",
    "    PrimerTermino = (1/(2*math.pi*math.sqrt(np.linalg.det(Sigma))))\n",
    "    \n",
    "    primerDot = np.dot((X-Mu),SigmaInversa)\n",
    "    segundoDot = np.dot(primerDot,(X-Mu).T)\n",
    "    Exponencial = math.exp(-0.5*segundoDot)\n",
    "    \n",
    "    Probabilidad = PrimerTermino * Exponencial\n",
    "    \n",
    "    return Probabilidad\n",
    "\n",
    "def FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo):\n",
    "    \n",
    "    N = Xtest.shape[0]\n",
    "    #Estimación de medias y Covarianzas\n",
    "    Mu1 = np.mean(Xtrain[(Ytrain==1).flat,:], axis=0)\n",
    "    Mu2 = np.mean(Xtrain[(Ytrain==0).flat,:], axis=0)\n",
    "  \n",
    "    Sigma1 = np.cov((Xtrain[(Ytrain==1).flat,:]).T)\n",
    "    Sigma2 = np.cov((Xtrain[(Ytrain==0).flat,:]).T)\n",
    "    \n",
    "    Sigma3 = (0.5*(Sigma1+Sigma2))\n",
    "    Yest = np.zeros(N)\n",
    "    Tipo = tipo\n",
    "    for i in range(N):\n",
    "        \n",
    "            if Tipo == 0 :\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma1)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma2)\n",
    "            elif Tipo == 1:\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma3)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma3)\n",
    "            if p1 >= p2:\n",
    "                Yest[i] = 1\n",
    "            else:\n",
    "                Yest[i] = 0\n",
    "                \n",
    "    return Yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 0 # Frontera lineal\n",
    "Yest0 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest0,Ytest)\n",
    "print('\\nError prueba (Frontera Lineal) = ' + str(Error))\n",
    "\n",
    "\n",
    "tipo = 1 #Frontera cuadrática\n",
    "Yest1 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest1,Ytest)\n",
    "print('\\nError prueba (Frontera cuadrática) = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 ¿Cuál tipo de frontera proporcionó mejores resultados?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Teniendo en cuenta la forma de los datos (De acuerdo con la gráfica hecha en el punto 2), expliqué porqué el modelo de Funciones Discriminantes Gaussianas obtiene un buen resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
